{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae71922-f609-432a-9457-56fac8f64f44",
   "metadata": {},
   "source": [
    "Q1: Probability Mass Function (PMF) and Probability Density Function (PDF) are mathematical functions used to describe the likelihood of different outcomes in a random variable.\n",
    "\n",
    "PMF: PMF is used for discrete random variables. It gives the probability of each possible outcome. For example, consider a fair six-sided die. The PMF would give the probability of rolling each of the numbers 1 through 6.\n",
    "\n",
    "PDF: PDF is used for continuous random variables. While it doesn't give the exact probability of a specific value (as the probability at a single point is zero in a continuous distribution), it gives the relative likelihood of the variable falling within a certain range. For example, in a normal distribution, the PDF describes how likely a data point is to fall within a given interval around the mean.\n",
    "\n",
    "Q2: Cumulative Density Function (CDF) is a function that gives the probability that a random variable takes a value less than or equal to a specified value. It's the integral of the PDF. CDF is used to determine probabilities for a range of values.\n",
    "\n",
    "Example of CDF: Consider a fair six-sided die. The CDF at value 3 would give the probability that rolling the die results in a value less than or equal to 3.\n",
    "\n",
    "Q3: The normal distribution is commonly used to model situations where data clusters around a central value, with fewer data points farther away from the mean. Examples include the distribution of heights and weights in a population, IQ scores, errors in measurements, etc.\n",
    "\n",
    "The parameters of the normal distribution are the mean (μ) and the standard deviation (σ). The mean determines the central point of the distribution, and the standard deviation determines the spread or width of the distribution. A larger standard deviation leads to a wider distribution.\n",
    "\n",
    "Q4: Importance of Normal Distribution: The normal distribution is important in statistics because of the Central Limit Theorem, which states that the distribution of sample means of a large number of independent, identically distributed random variables approaches a normal distribution, even if the original population is not normally distributed. This is crucial for many statistical inference techniques.\n",
    "\n",
    "Examples of Normal Distribution:\n",
    "\n",
    "Heights of individuals in a population.\n",
    "IQ scores in a population.\n",
    "Errors in measurements, like measuring temperature or distance.\n",
    "Q5: Bernoulli Distribution models a binary outcome, where an event can have one of two possible outcomes, usually labeled as 1 (success) and 0 (failure). Example: Coin flips, where 1 might represent \"heads\" and 0 might represent \"tails.\"\n",
    "\n",
    "Difference between Bernoulli and Binomial Distributions:\n",
    "\n",
    "Bernoulli is for a single trial.\n",
    "Binomial is for multiple independent, identical Bernoulli trials (e.g., multiple coin flips).\n",
    "Q6: To find the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 is greater than 60:\n",
    "\n",
    "Convert the value to a z-score: z = (60 - 50) / 10 = 1.\n",
    "Look up the z-score in a standard normal distribution table or use a calculator: P(Z > 1) ≈ 0.1587.\n",
    "Q7: Uniform Distribution is a continuous distribution where all values in the range have equal probability. An example is a fair roll of a six-sided die, where each number has a probability of 1/6.\n",
    "\n",
    "Q8: Z-score is the number of standard deviations a data point is from the mean. It's important because it allows us to compare different values from different normal distributions on a common scale.\n",
    "\n",
    "Q9: Central Limit Theorem (CLT) states that the distribution of the sample mean becomes approximately normal as the sample size increases, regardless of the original population's distribution. It's significant because it allows us to use normal distribution-based statistical methods even when the population distribution is not normal.\n",
    "\n",
    "Q10: Assumptions of the Central Limit Theorem:\n",
    "\n",
    "Independence: The random variables in the sample should be independent.\n",
    "Sample Size: The larger the sample size, the better the approximation to normality.\n",
    "Population Distribution: The population distribution should not be extremely skewed or have extreme outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4602a68-b45a-4a0c-a13b-32c52d0639b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
